{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.model import ShipDetector\n",
    "from src.utils import rle_decode, rle_encode\n",
    "from src.evaluation import compute_f2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdb379",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b53c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SAMPLE_IMAGE_SHOW_COUNT = 8  # number of sample images to visualize\n",
    "MODEL_CHOICE = \"yolo11n-seg.pt\"  # yolo11n-seg.pt, yolo11s-seg.pt, yolo11m-seg.pt, yolo11l-seg.pt, yolo11x-seg.pt\n",
    "\n",
    "# Path definitions\n",
    "ROOT_PATH = os.path.abspath(\".\")\n",
    "TEST_IMAGES_PATH = os.path.join(ROOT_PATH, \"data/test_v2\") # NOTE: I've used a subset of the train images for demo purposes\n",
    "TEST_LABELS_CSV = os.path.join(ROOT_PATH, \"data/test_ship_segmentations_v2.csv\") # NOTE: I've used a subset of the train images for demo purposes\n",
    "MODELS_PATH = os.path.join(ROOT_PATH, \"models\")\n",
    "MODEL_PATH = os.path.join(MODELS_PATH, MODEL_CHOICE)    # Will be automatically downloaded if not present\n",
    "OUTPUT_PATH = os.path.join(ROOT_PATH, \"outputs\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c95b9b",
   "metadata": {},
   "source": [
    "# Read and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4536c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labels\n",
    "df_test_labels = pd.read_csv(TEST_LABELS_CSV)\n",
    "\n",
    "# Extract sample images that has a mask\n",
    "sample_rows = df_test_labels[df_test_labels['EncodedPixels'].notna()].iloc[0:SAMPLE_IMAGE_SHOW_COUNT]  \n",
    "for index, sample_row in sample_rows.iterrows():\n",
    "    print(f\"ImageId: {sample_row['ImageId']}, EncodedPixels: {sample_row['EncodedPixels'][:30]}...\")\n",
    "    image_path = os.path.join(TEST_IMAGES_PATH, sample_row['ImageId'])\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    # Extract mask definition and decode\n",
    "    mask = rle_decode(sample_row['EncodedPixels'], image.shape[:2])\n",
    "\n",
    "    # Display image and mask\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1); plt.imshow(image); plt.title('Image')\n",
    "    plt.subplot(1,2,2); plt.imshow(mask); plt.title('Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0ea3a",
   "metadata": {},
   "source": [
    "# Model inference on examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize once\n",
    "detector = ShipDetector(MODEL_PATH, conf_threshold=0.1)\n",
    "\n",
    "# Get list of all some image paths to visualize\n",
    "image_files = os.listdir(TEST_IMAGES_PATH)[:SAMPLE_IMAGE_SHOW_COUNT]\n",
    "for i, image_file in enumerate(image_files):\n",
    "    \n",
    "    print(f\"Processing {i+1}/{len(image_files)} {image_file}\")\n",
    "    \n",
    "    # Get image name and full path\n",
    "    image_name, _ = os.path.splitext(image_file)\n",
    "    image_path = os.path.join(TEST_IMAGES_PATH, image_file)\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)[..., ::-1]\n",
    "    \n",
    "    # Get binary mask and contours\n",
    "    mask = detector.predict_mask(image)\n",
    "    contoured = detector.predict_contours(image)\n",
    "    \n",
    "    # Save image and mask\n",
    "    cv2.imwrite(os.path.join(OUTPUT_PATH, f\"{image_name}_predicted_mask.png\"), mask)\n",
    "    cv2.imwrite(os.path.join(OUTPUT_PATH, f\"{image_name}_predicted_contours.png\"), contoured[..., ::-1])\n",
    "    print(f\"Saved {image_name}_predicted_mask.png and {image_name}_predicted_contours.png to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bc629",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf700f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_masks = []\n",
    "all_pred_masks = []\n",
    "\n",
    "# Iterate over each image in the test set\n",
    "for image_id, group in tqdm.tqdm(df_test_labels.groupby(\"ImageId\")):\n",
    "    gt_masks = []\n",
    "    \n",
    "    # Read image to get shape\n",
    "    image_path = os.path.join(TEST_IMAGES_PATH, image_id)\n",
    "    image = cv2.imread(image_path)[..., ::-1]\n",
    "\n",
    "    # Get (decoded) ground truth masks for this image\n",
    "    for encoded_pixels in group[\"EncodedPixels\"].dropna():\n",
    "        gt_mask = rle_decode(encoded_pixels, image.shape[:2])\n",
    "        gt_masks.append(gt_mask)\n",
    "                \n",
    "    # Get predicted masks for this image\n",
    "    pred_masks = detector.predict_instance_masks(image)\n",
    "    \n",
    "    # Save both ground truth and predicted masks for this image\n",
    "    all_gt_masks.append(gt_masks)\n",
    "    all_pred_masks.append(pred_masks)\n",
    "\n",
    "# Evaluate using F2 Score\n",
    "f2_score = compute_f2_score(all_pred_masks, all_gt_masks, iou_thresholds=np.arange(0.5, 1.0, 0.05))\n",
    "print(f\"F2 Score: {f2_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
